{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# external imports\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local imports\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folderstructure setup\n",
    "path = {'trainmap':'csv/trainsplit.csv',\n",
    "        'testmap':'csv/testsplit.csv',\n",
    "        'data_labeled':'data/train/',\n",
    "        'data_unlabeled':'data/test/'\n",
    "        }\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "# hyperparameters\n",
    "hparam = {'batch_size': 200,\n",
    "          'nr_epochs': 10,\n",
    "          'architecture_name':'standard',\n",
    "          'weight_decay': 0.0,\n",
    "          'dropout_rate': 0.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "from util.Readers import BasicReader as Reader\n",
    "trainset = Reader(path['trainmap'], path['data_labeled'])\n",
    "testset = Reader(path['testmap'], path['data_labeled'])\n",
    "trainloader = DataLoader(trainset, batch_size=hparam['batch_size'], shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=hparam['batch_size'], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################# initiating run #################\n",
      "run dir has been created in run/26_14_11_44/\n",
      "\n",
      "batch_size\t: 200\n",
      "nr_epochs\t: 10\n",
      "architecture_name\t: standard\n",
      "weight_decay\t: 0.0\n",
      "dropout_rate\t: 0.0\n",
      "\n",
      "Using cuda device\n",
      "################# initiated run ##################\n",
      "using STANDARD architecture\n",
      "beginning training 14:11:44\n",
      "epoch\t\tt_cost\t\tv_cost\t\tt_acc\t\tv_acc\t\ttime\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/test/L342F02061C39S12265Ip.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\study\\archive_code\\repo\\eog_challenge\\main.ipynb Cell 5\u001b[0m in \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/study/archive_code/repo/eog_challenge/main.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mNetworks\u001b[39;00m \u001b[39mimport\u001b[39;00m Orinet\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/study/archive_code/repo/eog_challenge/main.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m model \u001b[39m=\u001b[39m Orinet(hparam[\u001b[39m'\u001b[39m\u001b[39marchitecture_name\u001b[39m\u001b[39m'\u001b[39m], hparam[\u001b[39m'\u001b[39m\u001b[39mweight_decay\u001b[39m\u001b[39m'\u001b[39m], hparam[\u001b[39m'\u001b[39m\u001b[39mdropout_rate\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/study/archive_code/repo/eog_challenge/main.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m model\u001b[39m.\u001b[39;49mtrain_model(trainloader, testloader, hparam[\u001b[39m'\u001b[39;49m\u001b[39mnr_epochs\u001b[39;49m\u001b[39m'\u001b[39;49m], runpath, device)\n",
      "File \u001b[1;32md:\\study\\archive_code\\repo\\eog_challenge\\util\\Networks.py:86\u001b[0m, in \u001b[0;36mOrinet.train_model\u001b[1;34m(self, trainloader, testloader, nr_epochs, runpath, device)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, nr_epochs\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m     85\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_epoch(trainloader, device)\n\u001b[1;32m---> 86\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtest_epoch(testloader, device)\n\u001b[0;32m     87\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog_epoch(header, runpath, nr_epochs)\n",
      "File \u001b[1;32md:\\study\\archive_code\\repo\\eog_challenge\\util\\Networks.py:57\u001b[0m, in \u001b[0;36mOrinet.test_epoch\u001b[1;34m(self, valloader, device)\u001b[0m\n\u001b[0;32m     55\u001b[0m cost, accuracy \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m\n\u001b[0;32m     56\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad(): \u001b[39m# disable gradient calculation\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m     \u001b[39mfor\u001b[39;00m batch_x, batch_y, _ \u001b[39min\u001b[39;00m valloader:\n\u001b[0;32m     58\u001b[0m         x, y \u001b[39m=\u001b[39m batch_x\u001b[39m.\u001b[39mto(device), batch_y\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     59\u001b[0m         preds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m(x)\n",
      "File \u001b[1;32md:\\program\\code_language\\python_3.10\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32md:\\program\\code_language\\python_3.10\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32md:\\program\\code_language\\python_3.10\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32md:\\program\\code_language\\python_3.10\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32md:\\study\\archive_code\\repo\\eog_challenge\\util\\Readers.py:22\u001b[0m, in \u001b[0;36mBasicReader.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     20\u001b[0m label \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([row[\u001b[39m'\u001b[39m\u001b[39mextent\u001b[39m\u001b[39m'\u001b[39m]], dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)\n\u001b[0;32m     21\u001b[0m name \u001b[39m=\u001b[39m row[\u001b[39m'\u001b[39m\u001b[39mfilename\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m---> 22\u001b[0m image \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39;49mopen(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpath_im\u001b[39m+\u001b[39;49mname)\n\u001b[0;32m     23\u001b[0m image \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_size_uniform(image\u001b[39m=\u001b[39mimage, size\u001b[39m=\u001b[39m(\u001b[39m128\u001b[39m, \u001b[39m128\u001b[39m))\n\u001b[0;32m     24\u001b[0m \u001b[39mreturn\u001b[39;00m image, label, name\n",
      "File \u001b[1;32md:\\program\\code_language\\python_3.10\\lib\\site-packages\\PIL\\Image.py:3068\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3065\u001b[0m     filename \u001b[39m=\u001b[39m fp\n\u001b[0;32m   3067\u001b[0m \u001b[39mif\u001b[39;00m filename:\n\u001b[1;32m-> 3068\u001b[0m     fp \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39;49mopen(filename, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m   3069\u001b[0m     exclusive_fp \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   3071\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/test/L342F02061C39S12265Ip.jpg'"
     ]
    }
   ],
   "source": [
    "# begin\n",
    "from util.Tools import run_init\n",
    "runpath = run_init(hparams=hparam, device=device)\n",
    "\n",
    "from util.Networks import Orinet\n",
    "model = Orinet(hparam['architecture_name'], hparam['weight_decay'], hparam['dropout_rate']).to(device)\n",
    "model.train_model(trainloader, testloader, hparam['nr_epochs'], runpath, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
